<</mnt/linux-data/project/code/config.py>>
# Project path
PROJECT_PATH = "/mnt/linux-data"

# Simulation parameters
NUM_EPISODES = 100
MAX_STEPS_PER_EPISODE = 5

# Target configuration
TARGET_IP = "192.168.56.101"

# Model configuration
LLAMA_RUN = f"{PROJECT_PATH}/project/code/models/llama.cpp/build/bin/llama-run"
MODEL_PATH = f"file://{PROJECT_PATH}/project/code/models/nous-hermes/Nous-Hermes-2-Mistral-7B-DPO.Q4_K_M.gguf"

# Wordlists paths
WORDLISTS = {
    "gobuster_common": f"{PROJECT_PATH}/wordlists/SecLists/Discovery/Web-Content/common.txt"
}

# LLM cache path
LLM_CACHE_PATH = f"{PROJECT_PATH}/project/code/Cache/llm_cache.pkl"

CVE_PATH = f"{PROJECT_PATH}/project/code/datasets/all_cves_combined.json"

#Blackboard path
BLACKBOARD_PATH = f"{PROJECT_PATH}/project/code/blackboard/blackboard.json"
<</mnt/linux-data/project/code/main.py>>
import torch
from config import NUM_EPISODES, MAX_STEPS_PER_EPISODE, LLAMA_RUN, MODEL_PATH, TARGET_IP, CVE_PATH

from blackboard.blackboard import initialize_blackboard
from blackboard.api import BlackboardAPI

from replay_buffer.Prioritized_Replay_Buffer import PrioritizedReplayBuffer

from agents.agent_manager import AgentManager
from agents.recon_agent import ReconAgent
from agents.vuln_agent import VulnAgent, load_cve_database

from orchestrator.scenario_orchestrator import ScenarioOrchestrator

from models.policy_model import PolicyModel
from models.trainer import RLModelTrainer
from models.llm.llama_interface import LlamaModel

from encoders.state_encoder import StateEncoder
from encoders.action_encoder import ActionEncoder

from tools.action_space import get_commands_for_agent

def main():

    # LLM Model
    model = LlamaModel(LLAMA_RUN, MODEL_PATH)

    # Load cve dataset
    cve_items = load_cve_database(CVE_PATH)
    print("✅ CVE dataset Loaded successfully.")

    # Replay Buffer
    replay_buffer = PrioritizedReplayBuffer(max_size=20000)

    # Action Space
    action_space = get_commands_for_agent("recon", TARGET_IP)
    action_encoder = ActionEncoder(action_space)
    state_encoder = StateEncoder(action_space=action_space)

    # Policy Model
    state_size = 128
    action_size = len(action_space)
    policy_model = PolicyModel(state_size=state_size, action_size=action_size)

    # Move to GPU if available
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    policy_model.to(device)

    # Trainer
    trainer = RLModelTrainer(
    policy_model=policy_model,
    replay_buffer=replay_buffer,
    device=device,
    learning_rate=1e-3,
    gamma=0.99
    )

    command_cache = {}
    all_actions = []

    # === EPISODE LOOP ===
    for episode in range(NUM_EPISODES):
        print(f"\n========== EPISODE {episode + 1} ==========")

        # --- Initialize Blackboard ---
        blackboard_dict = initialize_blackboard()
        blackboard_dict["target"]["ip"] = TARGET_IP
        bb_api = BlackboardAPI(blackboard_dict)

        # --- Create Recon Agent ---
        recon_agent = ReconAgent(
            blackboard_api=bb_api,
            policy_model=policy_model,
            replay_buffer=replay_buffer,
            state_encoder=state_encoder,
            action_encoder=action_encoder,
            command_cache=command_cache,
            model=model
        )
        
        # --- Create vuln Agent ---
        vuln_agent = VulnAgent(
            blackboard_api=bb_api,
            cve_items=cve_items
        )

        # --- Register Agents ---
        agents = [recon_agent, vuln_agent]
        agent_manager = AgentManager(bb_api)
        agent_manager.register_agents(agents)

        # --- Run Scenario ---
        scenario_name = f"AttackEpisode_{episode + 1}"
        orchestrator = ScenarioOrchestrator(
            blackboard=bb_api,
            agent_manager=agent_manager,
            max_steps=MAX_STEPS_PER_EPISODE,
            scenario_name=scenario_name,
            target=TARGET_IP
        )
        orchestrator.run_scenario_loop()

        # --- Track actions taken ---
        all_actions.append({
            "episode": episode + 1,
            "actions": recon_agent.actions_history.copy()
        })

        # --- Train Policy Model ---
        for _ in range(10):
            loss = trainer.train_batch(batch_size=32)
            if loss is not None:
                print(f"[Episode {episode + 1}] Training loss: {loss:.4f}")

    #print("\n========== SUMMARY OF ALL EPISODES ==========")
    #for episode_info in all_actions:
    #    print(f"Episode {episode_info['episode']}: {episode_info['actions']}")

    trainer.save_model("models/saved_models/policy_model.pth")
    print("✅ Final trained model saved.")

if __name__ == "__main__":
    main()

<</mnt/linux-data/project/code/replay_buffer/Prioritized_Replay_Buffer.py>>
import random
import numpy as np
import torch


class PrioritizedReplayBuffer:
    def __init__(self, max_size=100_000, alpha=0.6, beta=0.4):
        """
        A prioritized experience replay buffer for deep Q-learning.

        Args:
            max_size (int): Maximum number of experiences to store.
            alpha (float): Priority exponent (how much prioritization is used).
            beta (float): Importance-sampling exponent (how much to correct for bias).
        """
        self.max_size = max_size
        self.alpha = alpha
        self.beta = beta

        self.buffer = []
        self.priorities = []

    def add_experience(self, state, action, reward, next_state, done):
        """
        Add a new experience to the buffer with maximum priority.

        Args:
            state (Tensor): Current state.
            action (int): Action taken.
            reward (float): Reward received.
            next_state (Tensor): Next state.
            done (bool): Whether the episode ended.
        """
        max_priority = max(self.priorities) if self.buffer else 1.0
        experience = {
            "state": state,
            "action": action,
            "reward": reward,
            "next_state": next_state,
            "done": done
        }

        if len(self.buffer) >= self.max_size:
            self.buffer.pop(0)
            self.priorities.pop(0)

        self.buffer.append(experience)
        self.priorities.append(max_priority)

    def sample_batch(self, batch_size):
        """
        Sample a batch of experiences according to their priority.

        Args:
            batch_size (int): Number of experiences to sample.

        Returns:
            Tuple of tensors: (states, actions, rewards, next_states, dones, weights, indices)
        """
        if len(self.buffer) == 0:
            raise ValueError("The replay buffer is empty.")

        priorities = np.array(self.priorities, dtype=np.float32)
        scaled_priorities = priorities ** self.alpha
        sampling_probs = scaled_priorities / scaled_priorities.sum()

        indices = np.random.choice(len(self.buffer), size=batch_size, p=sampling_probs)
        experiences = [self.buffer[i] for i in indices]

        weights = (len(self.buffer) * sampling_probs[indices]) ** -self.beta
        weights = weights / weights.max()

        states = torch.stack([exp["state"] for exp in experiences])
        actions = torch.tensor([exp["action"] for exp in experiences])
        rewards = torch.tensor([exp["reward"] for exp in experiences])
        next_states = torch.stack([exp["next_state"] for exp in experiences])
        dones = torch.tensor([exp["done"] for exp in experiences])

        return states, actions, rewards, next_states, dones, torch.tensor(weights, dtype=torch.float32), indices

    def update_priorities(self, indices, new_priorities):
        """
        Update the priority of sampled experiences.

        Args:
            indices (List[int]): Indices of the sampled experiences.
            new_priorities (List[float]): Updated priority values.
        """
        for idx, priority in zip(indices, new_priorities):
            self.priorities[idx] = priority

    def size(self):
        """
        Return the number of stored experiences.
        """
        return len(self.buffer)

    def clear(self):
        """
        Clear all experiences and priorities.
        """
        self.buffer.clear()
        self.priorities.clear()

<</mnt/linux-data/project/code/agents/base_agent.py>>
import random
import subprocess
import json
import torch
from abc import ABC, abstractmethod

from Cache.llm_cache import LLMCache

from utils.prompts import PROMPT_1, PROMPT_2, clean_output_prompt, PROMPT_FOR_A_PROMPT
from utils.utils import remove_comments_and_empty_lines, extract_json_block, one_line
from utils.state_check.state_validator import validate_state
from utils.state_check.state_correctness import correct_state
from utils.json_fixer import fix_json

def remove_untrained_categories(state: dict, categories : set):
    for categorie in categories:
        state.pop(categorie, None)  

class BaseAgent(ABC):
    """
    Abstract base class for all AI agents in the attack environment.
    Provides the main learning and acting loop, caching, output parsing, and interaction with the blackboard.
    """

    def __init__(self, name, action_space, blackboard_api, replay_buffer,
                 policy_model, state_encoder, action_encoder, command_cache, model, epsilon=0.1):
        self.name = name
        self.action_space = action_space
        self.blackboard_api = blackboard_api
        self.replay_buffer = replay_buffer
        self.policy_model = policy_model
        self.state_encoder = state_encoder
        self.action_encoder = action_encoder
        self.command_cache = command_cache
        self.model = model
        self.epsilon = epsilon
        self.actions_history = []
        self.last_state = None
        self.last_action = None
        self.llm_cache = LLMCache(state_encoder=state_encoder)

    @abstractmethod
    def should_run(self) -> bool:
        """
        Must be implemented by subclasses to decide whether the agent should act now.
        """
        raise NotImplementedError
    
    @abstractmethod
    def get_reward(self, prev_state, action, next_state) -> float:
        """
        Must be implemented by subclasses to compute the reward signal.
        """
        raise NotImplementedError

    def run(self):
        """
        Main loop of the agent: observe, choose action, perform, parse, learn, update.
        """
        #step 1: fill state withh all categories
        self.blackboard_api.fill_state(
            actions_history=self.actions_history.copy(),
            )
        # Step 1: get state
        state = dict(self.get_state_raw())
        encoded_state = self.state_encoder.encode(state, self.actions_history)
        self.last_state = state

        # [DEBUG]
        print(f"last state: {json.dumps(state, indent=2)}")

        # Step 2: select action
        action = self.choose_action(encoded_state)
        self.last_action = action
        self.actions_history.append(action)

        print(f"\n[+] Agent: {self.name}")
        print(f"    Current state: {str(state)[:8]}...")
        print(f"    Chosen action: {action}")

        # Step 3: execute action
        result = remove_comments_and_empty_lines(self.perform_action(action))
        print("\033[1;32m" + str(result) + "\033[0m")

        # Step 4: clean output (if long)
        if len(result.split()) > 300:
            try:
                cleaned_output = self.clean_output(clean_output_prompt(result))
            except Exception as e:
                print(f"[!] Failed to clean output: {e}")
                cleaned_output = result
        else:
            cleaned_output = result
        print(f"\033[94mcleaned_output - {cleaned_output}\033[0m")

        # Step 5: parse, validate and update blackboard
        parsed_info = self.parse_output(cleaned_output)
        print(f"parsed_info - {parsed_info}")

        parsed_info = self.check_state(parsed_info)
        print(type(parsed_info))
        
        self.blackboard_api.update_state(parsed_info, self.name)

        # Step 6: observe next state
        next_state = dict(self.get_state_raw())
        encoded_next_state = self.state_encoder.encode(next_state, self.actions_history)

        # Step 7: reward and update model
        reward = self.get_reward(encoded_state, action, encoded_next_state)
        print(f"new state: {json.dumps(dict(self.state_encoder.decode(encoded_next_state)), indent=2)}")

        experience = {
            "state": encoded_state,
            "action": self.action_space.index(action),
            "reward": reward,
            "next_state": encoded_next_state
        }

        q_pred, loss = self.policy_model.update(experience)

        print(f"    Predicted Q-value: {q_pred:.4f}")
        print(f"    Actual reward:     {reward:.4f}")
        print(f"    Loss:              {loss:.6f}")

        # Step 8: save experience
        self.replay_buffer.add_experience(encoded_state, self.action_space.index(action), reward, encoded_next_state, False)

        # Step 9: log action
        self.blackboard_api.append_action_log({
            "agent": self.name,
            "action": action,
            "result": result,
        })

    def choose_action(self, state_vector):
        """
        ε-greedy policy: choose random action with probability ε, else best predicted action.
        """
        if random.random() < self.epsilon:
            action_index = random.randint(0, len(self.action_space) - 1)
            self.decay_epsilon()
        else:
            action_index = self.policy_model.predict_best_action(state_vector)

        return self.action_space[action_index]

    def decay_epsilon(self, decay_rate=0.995, min_epsilon=0.01):
        """
        Gradually reduce exploration probability.
        """
        self.epsilon = max(self.epsilon * decay_rate, min_epsilon)

    def get_state_raw(self):
        """
        Get the current blackboard state as-is (used for encoding).
        """
        return self.blackboard_api.get_state_for_agent(self.name)

    def get_state(self):
        """
        Encoded state vector.
        """
        return self.state_encoder.encode(self.get_state_raw(), self.actions_history)

    def perform_action(self, action: str) -> str:
        """
        Default behavior: run an IP-based shell command with the action template.
        """
        ip = self.blackboard_api.blackboard.get("target", {}).get("ip", "127.0.0.1")
        command = action.format(ip=ip)

        if action in self.command_cache:
            print(f"[Cache] Returning cached result for action: {action}")
            return self.command_cache[action]

        try:
            output = subprocess.check_output(command.split(), timeout=10).decode()
        except Exception as e:
            self.blackboard_api.add_error(self.name, action, str(e))
            output = ""

        self.command_cache[action] = output
        return output

    def parse_output(self, command_output: str) -> dict:
        """
        Parse command output using the LLM. Use cache if available.
        """
        state = self.get_state_raw()

        cached = self.llm_cache.get(state, self.last_action)
        if cached:
            print("\033[93m[CACHE] Using cached LLM result.\033[0m")
            return cached

        untrained_categories = {"actions_history","vulnerabilities_found", "cpes"}
        remove_untrained_categories(state, untrained_categories)
        
        # [DEBUG]
        print(f"state full: {state}")

        prompt_for_prompt = PROMPT_FOR_A_PROMPT(command_output)
        inner_prompt = self.model.run([prompt_for_prompt])[0]
        final_prompt = PROMPT_2(command_output, inner_prompt)

        responses = self.model.run([
            one_line(PROMPT_1(json.dumps(self.get_state_raw(), indent=2))),
            one_line(final_prompt)
        ])
        
        full_response = responses[1]
        print(f"full_response - {full_response}")

        parsed = fix_json(str(full_response))
        if parsed is None:
            print("⚠️ parsed is None – skipping this round safely.")
            return self.get_state_raw()
        if parsed:
            self.llm_cache.set(state, self.last_action, parsed)

        return parsed

    def clean_output(self, command_output: str) -> dict:
        """
        Clean long noisy outputs using a cleanup prompt and the LLM.
        """
        return self.model.run_prompt(clean_output_prompt(command_output))

    def update_policy(self, state, action, reward, next_state):
        """
        Manually trigger an update to the Q-network.
        """
        self.policy_model.update({
            "state": state,
            "action": self.action_space.index(action),
            "reward": reward,
            "next_state": next_state
        })

    def check_state(self, current_state: str):
        # Validate and correct the state
        new_state = validate_state(current_state)
        print(f"validate_state: {new_state}")
        
        # Correct the state based on predefined rules
        new_state = correct_state(new_state)
        print(f"correct_state: {new_state}")

        # Ensure the state is a dictionary
        if not isinstance(new_state, dict):
            print(f"[!] Warning: Invalid state type received. Converting to dictionary...")
            new_state = dict(new_state)

        return new_state

<</mnt/linux-data/project/code/agents/recon_agent.py>>
import json
import hashlib
from agents.base_agent import BaseAgent
from tools.action_space import get_commands_for_agent


class ReconAgent(BaseAgent):
    """
    A specialized agent for reconnaissance actions in the attack simulation.
    It selects and executes recon commands to gather service and network info.
    """

    def __init__(self, blackboard_api, policy_model, replay_buffer, state_encoder, action_encoder, command_cache, model):
        """
        Initialize the ReconAgent with access to the blackboard and learning components.

        Args:
            blackboard_api (BlackboardAPI): Shared state interface.
            policy_model (PolicyModel): Q-network.
            replay_buffer: Experience replay buffer.
            state_encoder: State vector encoder.
            action_encoder: Action index encoder.
            command_cache: Shared cache of previously executed commands.
            model: LLM interface used for output parsing.
        """
        ip = blackboard_api.blackboard["target"]["ip"]
        super().__init__(
            name="ReconAgent",
            blackboard_api=blackboard_api,
            action_space=get_commands_for_agent("recon", ip),
            policy_model=policy_model,
            replay_buffer=replay_buffer,
            state_encoder=state_encoder,
            action_encoder=action_encoder,
            command_cache=command_cache,
            model=model
        )

    def should_run(self):
        """
        Determine whether the agent should run in the current blackboard state.

        Returns:
            bool: True if the agent should act, False otherwise.
        """
        bb = self.blackboard_api.blackboard
        target = bb.get("target", {})
        runtime = bb.get("runtime_behavior", {})
        actions_log = bb.get("actions_log", [])
        errors = bb.get("errors", [])
        impact = bb.get("attack_impact", {})

        services = target.get("services", [])
        open_ports = target.get("open_ports", [])

        # 1. No services or ports yet
        if not services and not open_ports:
            return True

        # 2. Too few results
        if len(services) < 2 and len(open_ports) < 2:
            return True

        # 3. Errors from this agent
        for err in errors:
            if err.get("agent") == self.name:
                return True

        # 4. Hasn't run recently
        last_time = None
        for log in reversed(actions_log):
            if log.get("agent") == self.name:
                last_time = log.get("timestamp")
                break
        if last_time is None:
            return True

        import time
        if time.time() - last_time > 300:
            return True

        # 5. Shell already open
        shell = runtime.get("shell_opened", {})
        if shell.get("shell_type") and shell.get("shell_access_level"):
            return False

        # 6. Detected by defenses
        if impact.get("detected_by_defenses", False):
            return False

        # ----- DEBUG ----- #
        if prev_dict.get("os"):
            return False

        return True

    def get_reward(self, prev_state, action, next_state) -> float:
        """
        Calculate the reward based on changes in knowledge or system state.

        Args:
            prev_state: Previous state vector.
            action (str): Action that was taken.
            next_state: Resulting state vector.

        Returns:
            float: The reward value for this transition.
        """
        reward = 0.0
        reasons = []

        def _services_to_set(services):
            return set(
                (s.get("port", ""), s.get("protocol", ""), s.get("service", ""))
                for s in services if isinstance(s, dict)
            )

        try:
            prev_key = str(prev_state.tolist())
            next_key = str(next_state.tolist())

            prev_dict = self.state_encoder.encoded_to_state.get(prev_key, {})
            next_dict = self.state_encoder.encoded_to_state.get(next_key, {})

            actions_history = prev_dict.get("actions_history", [])

            # Repeated action penalty
            if action in actions_history:
                reward -= 0.5
                reasons.append("Repeated action -0.5")
            else:
                reward += 0.2
                reasons.append("New action +0.2")

            # New services discovered
            prev_services = _services_to_set(prev_dict.get("target", {}).get("services", []))
            next_services = _services_to_set(next_dict.get("target", {}).get("services", []))
            new_services = next_services - prev_services
            reward += 1.0 * len(new_services)
            if new_services:
                reasons.append(f"{len(new_services)} new services discovered +{1.0 * len(new_services):.1f}")

            # New ports discovered
            prev_ports = set(prev_dict.get("target", {}).get("open_ports", []))
            next_ports = set(next_dict.get("target", {}).get("open_ports", []))
            new_ports = next_ports - prev_ports
            reward += 0.5 * len(new_ports)
            if new_ports:
                reasons.append(f"{len(new_ports)} new open ports +{0.5 * len(new_ports):.1f}")

            # New shell opened
            prev_shell = prev_dict.get("runtime_behavior", {}).get("shell_opened", {})
            next_shell = next_dict.get("runtime_behavior", {}).get("shell_opened", {})

            if not prev_shell.get("shell_type") and next_shell.get("shell_type"):
                reward += 5.0
                reasons.append("New shell opened +5.0")

            # Privilege escalation
            levels = {"": 0, "user": 1, "root": 2}
            prev_level = prev_shell.get("shell_access_level", "")
            next_level = next_shell.get("shell_access_level", "")
            if levels.get(next_level, 0) > levels.get(prev_level, 0):
                reward += 3.0
                reasons.append(f"Privilege escalation from {prev_level} to {next_level} +3.0")

            # Useless repetition penalty
            if not new_services and not new_ports and not next_shell.get("shell_type"):
                if action in actions_history:
                    reward -= 1.0
                    reasons.append("No new discoveries and repeated action -1.0")

            # Debug summary
            print(f"[Reward Debug] Action: {action}")
            print(f"[Reward Debug] New services: {len(new_services)}")
            print(f"[Reward Debug] New ports: {len(new_ports)}")
            print(f"[Reward Debug] Shell opened: {next_shell.get('shell_type')}")
            print(f"[Reward Debug] Total reward: {reward:.4f}")

            print("\n[Reward Summary]")
            print(f"Action: {action}")
            print("Reasons:")
            for r in reasons:
                print(f" - {r}")
            print(f"Total reward: {reward:.4f}\n")

            return reward

        except Exception as e:
            print(f"[!] Reward computation failed: {e}")
            return 0.0
<</mnt/linux-data/project/code/agents/vuln_agent.py>>
import json
import re
import fnmatch
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from config import TARGET_IP, LLAMA_RUN, MODEL_PATH, CVE_PATH
from agents.base_agent import BaseAgent

def load_cve_database(cve_path: str):
    """
    Loads and normalizes the CVE database from the given JSON file.

    Returns:
        List[dict]: List of CVE items (parsed and ready).
    """
    with open(cve_path, "r", encoding="utf-8") as f:
        data = json.load(f)

        if isinstance(data, list):
            return data

        elif isinstance(data, dict) and "CVE_Items" in data:
            return data["CVE_Items"]

        else:
            raise ValueError("❌ Unsupported CVE format: expected list or dict with 'CVE_Items'")

def extract_all_cpe_matches(node):
    """
    Recursively extract all 'cpe_match' entries from a node and its children.
    """
    matches = []

    if "cpe_match" in node:
        matches.extend(node["cpe_match"])

    if "children" in node:
        for child in node["children"]:
            matches.extend(extract_all_cpe_matches(child))

    return matches
    
class VulnAgent(BaseAgent):
    """
    Agent that scans for CVEs matching known CPEs based on current state.
    """

    def __init__(self, blackboard_api, cve_items):
        super().__init__(
            name="VulnAgent",
            action_space=[],  # No actions
            blackboard_api=blackboard_api,
            replay_buffer=None,
            policy_model=None,
            state_encoder=None,
            action_encoder=None,
            command_cache={},
            model=None
        )
        self.cve_items = cve_items

    def should_run(self) -> bool:
        state = self.blackboard_api.get_state_for_agent(self.name)
        return True

    def get_reward(self, prev_state, action, next_state) -> float:
        return 0.0  # This agent does not learn

    def run(self):
        print("[+] VulnAgent running...")
        state = self.blackboard_api.get_state_for_agent(self.name)
        possible_cpes = self.generate_possible_cpes(state)

        found_vulns = self.match_cves_to_cpes(possible_cpes)

        print(f"[VulnAgent] Found {len(found_vulns)} matching CVEs")
        self.blackboard_api.blackboard["vulnerabilities_found"] = found_vulns

    def match_cves_to_cpes(self, possible_cpes):
        """
        Compare possible CPEs from current state to CVE database and return matching entries.
        Supports recursive search of cpe_match in nodes and nested children.
        """
        vuln_dict = {}

        for item in self.cve_items:
            try:
                cve_id = item["cve"]["CVE_data_meta"]["ID"]
                configurations = item.get("configurations", {})
                nodes = configurations.get("nodes", [])

                for node in nodes:
                    all_cpe_matches = extract_all_cpe_matches(node)

                    for match in all_cpe_matches:
                        match_cpe = match.get("cpe23Uri", "").lower()

                        for my_cpe in possible_cpes:
                            my_cpe = my_cpe.lower()

                            # התאמה רגילה עם תווים כלליים
                            if fnmatch.fnmatch(match_cpe, my_cpe):
                                vuln_dict.setdefault(cve_id, {"cve": cve_id, "matched_cpes": []})["matched_cpes"].append(match_cpe)
                                break

                            # התאמה לפי מילות מפתח בהקשר של HTTP
                            if "http" in my_cpe and "http" in match_cpe:
                                vuln_dict.setdefault(cve_id, {"cve": cve_id, "matched_cpes": []})["matched_cpes"].append(match_cpe)
                                break

            except Exception as e:
                print(f"[!] Failed parsing CVE {item.get('cve', {}).get('CVE_data_meta', {}).get('ID', 'unknown')}: {e}")
                continue

        return list(vuln_dict.values())

    def generate_possible_cpes(self, state_dict):
        """
        Generate all possible CPE 2.3 URIs from OS, services and web directories using a generic strategy.
        """
        cpes = set()
        target = state_dict.get("target", {})

        # === OS to CPE ===
        os_raw = target.get("os", "").strip().lower()
        if os_raw:
            vendor = os_raw.replace(" ", "_")
            product = os_raw.replace(" ", "_")
            cpes.add(f"cpe:2.3:o:{vendor}:{product}:*:*:*:*:*:*:*:*")

        # === Services to CPE ===
        services = target.get("services", [])
        for s in services:
            name = str(s.get("service", "")).strip().lower().replace(" ", "_")
            if not name:
                continue
            vendor = product = name
            cpes.update(self._generate_service_cpes(vendor, product))

        # === Web Directories Heuristics ===
        dirs = state_dict.get("web_directories_status", {})
        for code in ["200", "403"]:  # ננסה להוציא מזה מערכות קיימות
            paths = dirs.get(code, {})
            for path in paths:
                dir_name = path.strip("/").lower()
                if not dir_name or "/" in dir_name:
                    continue  # נתעלם מתיקיות ריקות או עמוקות מדי
                vendor = product = dir_name.replace("-", "_")
                cpes.update(self._generate_service_cpes(vendor, product))

        print(f"[VulnAgent] Generated {len(cpes)} possible CPEs (OS + Services + Web Heuristics).")
        return list(cpes)

    def _generate_service_cpes(self, vendor, product):
        """
        Helper to generate multiple flexible CPE patterns for a given vendor/product.
        """
        return {
            f"cpe:2.3:a:{vendor}:{product}:*:*:*:*:*:*:*:*",
            f"cpe:2.3:a:*:{product}:*:*:*:*:*:*:*:*",
            f"cpe:2.3:a:{vendor}:*:*:*:*:*:*:*:*:*"
        }

# DEBUG
if __name__ == "__main__":

    print("[*] Loading CVE database...")
    cve_items = load_cve_database(CVE_PATH)
    print(f"[+] Loaded {len(cve_items)} CVE entries")

    # מצב בדיקה ידני
    test_state = {
        "target": {
            "ip": "192.168.56.101",
            "os": "Linux",
            "services": [
                {"port": "80", "protocol": "tcp", "service": "apache"},
                {"port": "3306", "protocol": "tcp", "service": "mysql"}
            ]
        },
        "web_directories_status": {
            "200": {
                "/phpmyadmin/": "",
                "/dvwa/": ""
            },
            "403": {
                "/webdav/": ""
            }
        }
    }

    # מחלקת dummy כדי לדמות את ה-API
    class DummyBlackboardAPI:
        def get_state_for_agent(self, name):
            return test_state

        @property
        def blackboard(self):
            return {}

    # צור את הסוכן והפעל את הפונקציות
    agent = VulnAgent(blackboard_api=DummyBlackboardAPI(), cve_items=cve_items)

    possible_cpes = agent.generate_possible_cpes(test_state)
    matches = agent.match_cves_to_cpes(possible_cpes)

    print(f"\n[✓] Found {len(matches)} matching CVEs")
    for match in matches[:10]:  # מדפיס את 10 הראשונים בלבד
        print(f"  - {match['cve']}: {len(match['matched_cpes'])} matched CPEs")
        for cpe in match["matched_cpes"]:
            print(f"    • {cpe}")

<</mnt/linux-data/project/code/agents/agent_manager.py>>
class AgentManager:
    """
    Manages the lifecycle and execution of multiple agents within an attack scenario.
    Supports agent registration, turn-based or full execution, logging, and pending checks.
    """

    def __init__(self, blackboard_api):
        """
        Initialize the AgentManager with access to the shared blackboard.

        Args:
            blackboard_api: Instance of BlackboardAPI for shared state.
        """
        self.agents = []
        self.blackboard = blackboard_api
        self.current_index = 0
        self.execution_log = []
        self.actions_history = []

    def register_agents(self, agent_list):
        """
        Register a new list of agents and reset execution state.

        Args:
            agent_list (list): List of agent instances to register.
        """
        self.agents = agent_list
        self.current_index = 0
        self.execution_log.clear()
        self.actions_history.clear()

    def run_all(self):
        """
        Run all agents whose `should_run()` method returns True.
        """
        for agent in self.agents:
            if agent.should_run():
                agent.run()
                self.execution_log.append(agent.name)
                self.actions_history.append(agent.last_action)

    def run_step(self):
        """
        Run the next agent in a round-robin fashion if it's ready to act.
        """
        if not self.agents:
            return

        agent = self.agents[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.agents)

        if agent.should_run():
            agent.run()
            self.execution_log.append(agent.name)
            self.actions_history.append(agent.last_action)

    def has_pending_actions(self) -> bool:
        """
        Check if any registered agent is still eligible to act.

        Returns:
            bool: True if at least one agent should run, otherwise False.
        """
        return any(agent.should_run() for agent in self.agents)

    def log_summary(self):
        """
        Print a summary of which agents executed in the last round.
        """
        print("Agents executed in this round:")
        for name in self.execution_log:
            print(f"- {name}")
        print("Executed actions:")
        for action in self.actions_history:
            print(f"  → {action}")

<</mnt/linux-data/project/code/agents/llm_parser_agent.py>>
# agents/llm_parser_agent.py

from agents.base_agent import BaseAgent
from utils.utils import extract_json_block
from utils.prompts import PROMPT_1, PROMPT_2, PROMPT_FOR_A_PROMPT
from utils.prompts import clean_output_prompt

class LLMParserAgent(BaseAgent):
    """
    Agent for parsing raw command outputs into structured blackboard-compatible JSON
    using a language model.
    """

    def __init__(self, blackboard_api, model):
        super().__init__(
            name="LLMParserAgent",
            action_space=[],  # No actions
            blackboard_api=blackboard_api,
            replay_buffer=None,
            policy_model=None,
            state_encoder=None,
            action_encoder=None,
            command_cache={},
            model=model
        )

    def should_run(self) -> bool:
        # Run if new raw output is present
        return bool(self.blackboard_api.blackboard.get("last_raw_output", ""))

    def get_reward(self, prev_state, action, next_state) -> float:
        # This agent doesn't participate in reward learning
        return 0.0

    def run(self):
        raw_output = self.blackboard_api.blackboard.get("last_raw_output", "")
        if not raw_output:
            print("[LLMParserAgent] No raw output to process.")
            return

        print("\n[+] LLMParserAgent running...")

        # 1. Create prompts
        prompt_for_prompt = PROMPT_FOR_A_PROMPT(raw_output)
        inner_prompt = self.model.run([prompt_for_prompt])[0]
        final_prompt = PROMPT_2(raw_output, inner_prompt)

        # 2. Run with context structure
        structure_prompt = PROMPT_1(self.blackboard_api.get_state_for_agent(self.name))
        responses = self.model.run([
            self.one_line(structure_prompt),
            self.one_line(final_prompt)
        ])

        # 3. Extract JSON
        full_response = responses[1] + "\n" + responses[0]
        print(f"[LLMParserAgent] full_response - {full_response}")

        parsed = extract_json_block(full_response)

        if parsed:
            # Post-fix structure if needed
            parsed = self.fix_json(parsed)
            print(f"[LLMParserAgent] Parsed JSON: {parsed}")
            self.blackboard_api.overwrite_blackboard(parsed)
        else:
            print("[LLMParserAgent] ❌ Failed to extract valid JSON.")

    def one_line(self, text: str) -> str:
        return ' '.join(line.strip() for line in text.strip().splitlines() if line).replace('  ', ' ')

    def fix_json(self, parsed: dict) -> dict:
        """
        Ensures the parsed JSON strictly follows expected format.
        """
        required_statuses = ["200", "401", "403", "404", "503"]
        wds = parsed.get("web_directories_status", {})
        for status in required_statuses:
            if status not in wds or not isinstance(wds[status], dict) or not wds[status]:
                wds[status] = {"": ""}
        parsed["web_directories_status"] = wds

        # Ensure services list has exactly 3 entries
        services = parsed.get("target", {}).get("services", [])
        while len(services) < 3:
            services.append({"port": "", "protocol": "", "service": ""})
        parsed["target"]["services"] = services[:3]

        return parsed

<</mnt/linux-data/project/code/Cache/llm_cache.py>>
import os
import pickle

from config import LLM_CACHE_PATH

class LLMCache:
    """
    Caches LLM outputs to avoid redundant processing for identical state-action pairs.
    """

    def __init__(self, cache_file=LLM_CACHE_PATH, state_encoder=None):
        self.cache_file = cache_file
        self.state_encoder = state_encoder
        self.cache = self._load_cache()

    def _load_cache(self):
        """
        Loads the cache from disk if it exists.
        """
        if os.path.exists(self.cache_file):
            with open(self.cache_file, "rb") as f:
                return pickle.load(f)
        return {}

    def _save_cache(self):
        """
        Saves the current cache dictionary to disk.
        """
        with open(self.cache_file, "wb") as f:
            pickle.dump(self.cache, f)

    def _get_key(self, state_dict, actions_history, action_str):
        """
        Generates a unique key for the cache based on:
        - the encoded state (including action history)
        - the current action string
        """
        vector = self.state_encoder.encode(state_dict, actions_history)
        vector_key = str(vector.tolist())
        return f"{vector_key}||{action_str}"

    def get(self, state_dict, action_str, actions_history=[]):
        """
        Retrieves a cached result based on the state, history, and action.
        Returns None if no cached result exists.
        """
        key = self._get_key(state_dict, actions_history, action_str)
        return self.cache.get(key)

    def set(self, state_dict, action_str, value, actions_history=[]):
        """
        Stores a result in the cache for a specific state and action.
        """
        key = self._get_key(state_dict, actions_history, action_str)
        self.cache[key] = value
        self._save_cache()
<</mnt/linux-data/project/code/tools/action_space.py>>
from typing import List, Dict

from config import WORDLISTS

# Mapping of tool categories to their command templates
COMMAND_TEMPLATES: Dict[str, Dict[str, List[str]]] = {
    "recon": {
        "ping": [
            #"ping -c 1 {ip}"
        ],
        "nmap": [
            "nmap -F {ip}",
            "nmap {ip}"
        ],
        "curl": [
          #  "curl -I http://{ip}",
            #"curl http://{ip}/"
        ],
        "wget": [
       #     "wget http://{ip} -O -"
        ],
        "traceroute": [
          #  "traceroute {ip}"
        ],
        "whatweb": [
         #   "whatweb http://{ip}"
        ],
        "gobuster": [
          #  "gobuster dir -u http://{ip} -w /mnt/linux-data/wordlists/SecLists/Discovery/Web-Content/common.txt"
        ]
    },

    # Example future support:
    # "exploit": {
    #     "manual_exploit": [
    #         "python3 /path/to/exploit.py {ip}"
    #     ]
    # }
}

def build_action_space(agent_type: str, ip: str) -> List[str]:
    """
    Builds a list of actions for the given agent type and target IP address.

    Args:
        agent_type (str): Type of the agent (e.g., "recon", "exploit").
        ip (str): Target IP address.

    Returns:
        List[str]: List of formatted commands.
    """
    actions = []
    agent_type = agent_type.lower()

    if agent_type not in COMMAND_TEMPLATES:
        raise ValueError(f"Unknown agent type: '{agent_type}'")

    for tool, templates in COMMAND_TEMPLATES[agent_type].items():
        for cmd in templates:
            actions.append(cmd.format(ip=ip))

    return actions


def get_commands_for_agent(agent_type: str, ip: str) -> List[str]:
    """
    Retrieves a list of commands for a specific agent.

    Args:
        agent_type (str): Agent category ("recon", etc).
        ip (str): Target IP.

    Returns:
        List[str]: List of formatted commands.
    """
    return build_action_space(agent_type, ip)


if __name__ == "__main__":
    # Debug output of commands for a given IP and agent type
    target_ip = "192.168.56.101"
    commands = get_commands_for_agent("recon", target_ip)
    for cmd in commands:
        print(cmd)
<</mnt/linux-data/project/code/get_code/get_code.py>>
import os, tiktoken

def count_tokens(text):
    enc = tiktoken.get_encoding("cl100k_base")  # for GPT-4o
    return len(enc.encode(text, disallowed_special=()))

def print_all_python_files(start_dir, output_file):
    skip_dirs = {
        "llama.cpp",
        "nous-hermes",
        "__pycache__",
        "llama-factory",
        "hf_models",
        "Debug"
    }

    output = ''
    for root, dirs, files in os.walk(start_dir):
        dirs[:] = [d for d in dirs if d not in skip_dirs]

        for file in files:
            if file.endswith(".py"):
                path = os.path.join(root, file)
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        snippet = f"<<{path}>>\n{content}\n"
                        output += snippet
                        print(snippet)
                except Exception as e:
                    print(f"[ERROR] Failed to read {path}: {e}")

    with open(output_file, 'w', encoding='utf-8') as out_f:
        out_f.write(output)

    print(f"\n[Total Tokens (GPT-4o): {count_tokens(output)}]")
    print(f"[Saved to: {output_file}]")

print_all_python_files(
    "/mnt/linux-data/project/code",
    "/mnt/linux-data/project/code/get_code/code.txt"
)

<</mnt/linux-data/project/code/orchestrator/scenario_orchestrator.py>>
class ScenarioOrchestrator:
    """
    Manages the execution of a penetration testing scenario.

    This class controls:
    - Blackboard initialization per scenario
    - AgentManager coordination
    - Looping through steps
    - Stop conditions enforcement
    """

    def __init__(self, blackboard, agent_manager, target, max_steps=20, scenario_name="DefaultScenario", stop_conditions=None):
        """
        Initialize the orchestrator with simulation parameters.

        Args:
            blackboard: BlackboardAPI instance.
            agent_manager: AgentManager instance.
            target (str): Target IP address.
            max_steps (int): Maximum number of steps to execute.
            scenario_name (str): Human-readable name of the scenario.
            stop_conditions (list): Optional list of callables taking blackboard dict and returning True if scenario should stop.
        """
        self.blackboard = blackboard
        self.agent_manager = agent_manager
        self.max_steps = max_steps
        self.current_step = 0
        self.scenario_name = scenario_name
        self.stop_conditions = stop_conditions or []
        self.active = False
        self.target = target

    def start(self):
        """
        Initialize blackboard values and mark scenario as active.
        Resets internal step counter and blackboard state.
        """
        self.current_step = 0
        self.active = True

        # Initialize target structure
        self.blackboard.blackboard["target"] = {
            "ip": self.target,
            "os": "",
            "services": [
                {"port": "", "protocol": "", "service": ""},
                {"port": "", "protocol": "", "service": ""},
                {"port": "", "protocol": "", "service": ""}
            ]
        }

        # Initialize web directory status with all status codes
        self.blackboard.blackboard["web_directories_status"] = {
            "404": { "": "" },
            "200": { "": "" },
            "403": { "": "" },
            "401": { "": "" },
            "503": { "": "" }
        }

        print(f"[+] Starting scenario: {self.scenario_name}")

    def should_continue(self):
        """
        Check whether scenario should continue based on conditions.

        Returns:
            bool: True if scenario should continue, False if it should stop.
        """
        if not self.active:
            return False

        if self.current_step >= self.max_steps:
            print("[!] Max steps reached.")
            return False

        for condition in self.stop_conditions:
            if condition(self.blackboard.blackboard):
                print("[!] Stop condition met.")
                return False

        return True

    def step(self):
        """
        Execute a single simulation step by running the next eligible agent.
        """
        print(f"[>] Running step {self.current_step}...")
        self.agent_manager.run_step()
        self.current_step += 1

    def end(self):
        """
        Mark scenario as ended and print completion message.
        """
        self.active = False
        print(f"[+] Scenario '{self.scenario_name}' ended after {self.current_step} steps.")

    def run_scenario_loop(self):
        """
        Run full scenario loop from start to end.
        """
        self.start()
        while self.should_continue():
            self.step()
        self.end()

<</mnt/linux-data/project/code/models/policy_model.py>>
import torch
import torch.nn as nn
import torch.nn.functional as F

class PolicyModel(nn.Module):
    """
    A fully-connected Q-network for reinforcement learning.
    Maps input state vectors to Q-values for each action.
    """

    def __init__(self, state_size, action_size, hidden_sizes=[128, 64], learning_rate=1e-3, gamma=0.99):
        """
        Initialize the Q-network.

        Args:
            state_size (int): Size of the input state vector.
            action_size (int): Number of possible actions.
            hidden_sizes (list): List of hidden layer sizes (default: [128, 64]).
            learning_rate (float): Learning rate for the optimizer.
            gamma (float): Discount factor for future rewards.
        """
        super(PolicyModel, self).__init__()

        self.state_size = state_size
        self.action_size = action_size
        self.gamma = gamma

        self.fc1 = nn.Linear(state_size, hidden_sizes[0])
        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])
        self.output = nn.Linear(hidden_sizes[1], action_size)

        self.loss_fn = nn.MSELoss()
        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)

    def forward(self, state_vector):
        """
        Compute the Q-values for a given input state vector.

        Args:
            state_vector (Tensor or list): The input state representation.

        Returns:
            Tensor: Q-values for each possible action.
        """
        if not isinstance(state_vector, torch.Tensor):
            state_vector = torch.tensor(state_vector, dtype=torch.float32)

        if state_vector.ndim == 1:
            state_vector = state_vector.unsqueeze(0)  # Add batch dimension

        x = F.relu(self.fc1(state_vector))
        x = F.relu(self.fc2(x))
        return self.output(x)  # Raw Q-values

    def predict_best_action(self, state_vector):
        """
        Predict the index of the best action based on current Q-values.

        Args:
            state_vector (Tensor or list): Encoded state input.

        Returns:
            int: Index of action with the highest Q-value.
        """
        with torch.no_grad():
            q_values = self.forward(state_vector)
            return torch.argmax(q_values).item()

    def update(self, experience):
        """
        Perform a single Q-learning update based on one experience tuple.

        Args:
            experience (dict): Contains 'state', 'action', 'reward', 'next_state'.

        Returns:
            tuple: (predicted_q_value, loss_value)
        """
        state = experience["state"].clone().detach().unsqueeze(0)
        action = torch.tensor([experience["action"]], dtype=torch.long)
        reward = torch.tensor([experience["reward"]], dtype=torch.float32)
        next_state = experience["next_state"].clone().detach().unsqueeze(0)

        # Q(s, a)
        q_values = self.forward(state)
        q_value = q_values.gather(1, action.unsqueeze(1)).squeeze(1)

        # max_a' Q(next_state, a')
        next_q_values = self.forward(next_state)
        max_next_q_value = next_q_values.max(1)[0].detach()

        # TD Target
        td_target = reward + self.gamma * max_next_q_value
        td_target = td_target.view(-1)

        # Loss = MSE(Q, TD_target)
        loss = self.loss_fn(q_value, td_target)

        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        return q_value.item(), loss.item()

    def save(self, path):
        """
        Save the model weights to disk.

        Args:
            path (str): Path to save the model.
        """
        torch.save(self.state_dict(), path)

    def load(self, path):
        """
        Load the model weights from disk.

        Args:
            path (str): Path to load model from.
        """
        self.load_state_dict(torch.load(path))
        self.eval()
<</mnt/linux-data/project/code/models/trainer.py>>
import torch
import torch.nn as nn
import torch.optim as optim
import copy
import random


class RLModelTrainer:
    """
    A trainer class for reinforcement learning using Q-learning with experience replay.
    Supports prioritized experience buffers and a target network for stable learning.
    """

    def __init__(self, policy_model, replay_buffer, device='cpu', learning_rate=1e-3, gamma=0.99):
        """
        Initialize the trainer.

        Args:
            policy_model (nn.Module): The main Q-network.
            replay_buffer: Experience replay buffer.
            device (str): 'cpu' or 'cuda'.
            learning_rate (float): Optimizer learning rate.
            gamma (float): Discount factor for future rewards.
        """
        self.policy_model = policy_model.to(device)
        self.replay_buffer = replay_buffer
        self.device = device
        self.gamma = gamma

        self.optimizer = optim.Adam(self.policy_model.parameters(), lr=learning_rate)
        self.loss_fn = nn.MSELoss()

        self.training_history = []
        self.target_model = copy.deepcopy(policy_model).to(device)
        self.target_model.eval()

        self.update_target_steps = 100
        self.train_step = 0

    def train_batch(self, batch_size):
        """
        Sample a batch from the replay buffer and update the policy model.

        Args:
            batch_size (int): Number of experiences to train on.

        Returns:
            float or None: The loss value, or None if buffer too small.
        """
        if self.replay_buffer.size() < batch_size:
            return None  # Not enough data yet

        states, actions, rewards, next_states, dones, weights, indices = self.replay_buffer.sample_batch(batch_size)

        # Move tensors to device
        states = states.to(self.device)
        actions = actions.to(self.device)
        rewards = rewards.to(self.device)
        next_states = next_states.to(self.device)
        dones = dones.to(self.device)
        weights = torch.tensor(weights, dtype=torch.float32).to(self.device)

        # Q(s, a)
        q_values = self.policy_model.forward(states)
        current_q_values = q_values.gather(1, actions.unsqueeze(1)).squeeze(1)

        # max_a' Q(next_state, a')
        next_q_values = self.target_model.forward(next_states)
        max_next_q_values = next_q_values.max(1)[0]
        dones = dones.float()
        td_target = rewards + self.gamma * max_next_q_values * (1 - dones)
        td_target = td_target.detach()

        # TD Error & loss
        td_errors = torch.abs(current_q_values - td_target)
        loss = (weights * td_errors).mean()

        # Backpropagation
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        # Update target model if needed
        self.train_step += 1
        if self.train_step % self.update_target_steps == 0:
            self.target_model.load_state_dict(self.policy_model.state_dict())

        # Update priorities
        self.replay_buffer.update_priorities(indices, td_errors.detach().cpu().numpy())

        self.training_history.append(loss.item())
        return loss.item()

    def evaluate_action(self, state):
        """
        Evaluate Q-values for all actions given a state (no learning).

        Args:
            state (list or Tensor): Input state.

        Returns:
            ndarray: Q-values for each action.
        """
        with torch.no_grad():
            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)
            q_values = self.policy_model.forward(state_tensor)
            return q_values.cpu().numpy()

    def save_model(self, path):
        """
        Save the policy model to a file.

        Args:
            path (str): File path to save model.
        """
        torch.save(self.policy_model.state_dict(), path)

    def load_model(self, path):
        """
        Load the policy model from a file.

        Args:
            path (str): File path to load model from.
        """
        self.policy_model.load_state_dict(torch.load(path, map_location=self.device))
        self.policy_model.eval()

    def plot_learning_curve(self):
        """
        Plot the training loss over time.
        """
        if not self.training_history:
            print("No training history to plot.")
            return

        import matplotlib.pyplot as plt
        plt.plot(self.training_history)
        plt.xlabel("Training Steps")
        plt.ylabel("Loss")
        plt.title("Training Loss Curve")
        plt.grid(True)
        plt.show()

<</mnt/linux-data/project/code/models/llm/llama_interface.py>>
import os
import subprocess
import tiktoken

from models.llm.base_llm import BaseLLM
from utils.utils import one_line


class LlamaModel(BaseLLM):
    """
    LLM interface for executing prompts using llama.cpp binary.
    Supports single or multiple prompts with contextual memory.
    """

    def __init__(self, llama_path, model_path, tokens=3500, threads=4, n_batch=8192, context_size=500):
        self.llama_path = llama_path
        self.model_path = model_path
        self.tokens = str(tokens)
        self.threads = str(threads)
        self.n_batch = str(n_batch)
        self.context_size= str(context_size)

        if not os.path.isfile(self.llama_path):
            raise FileNotFoundError(f"llama-run binary not found: {self.llama_path}")
        if not self.model_path.startswith("file://"):
            raise ValueError("model_path must start with 'file://'")
        
        print("✅ Llama Model initialized successfully.")

    def count_tokens(self, text: str) -> int:
        """
        Count the number of tokens in a text string using cl100k_base tokenizer.
        """
        enc = tiktoken.get_encoding("cl100k_base")
        return len(enc.encode(text, disallowed_special=()))

    def run(self, prompts: list[str]) -> list[str]:
        """
        Run one or more prompts in sequence, maintaining conversational context.
        For a single prompt, just call run([prompt]).

        Args:
            prompts (list[str]): List of prompt strings.

        Returns:
            list[str]: List of model outputs, one per prompt.
        """
        responses = []
        context = ""

        for prompt in prompts:
            full_prompt = context + "\n" + prompt if context else prompt

            # === Debug Output ===
            print(f"[LLAMA] Prompt Tokens   ({self.count_tokens(prompt)}): {repr(prompt)}")
            print(f"[LLAMA] Context Tokens  ({self.count_tokens(context)}): {repr(context)}")
            print(f"[LLAMA] Full Tokens     ({self.count_tokens(full_prompt)}): {repr(full_prompt)}")

            cmd = [
                self.llama_path,
                self.model_path,
                full_prompt,
                "-n", self.tokens,
                "-t", self.threads,
                "--n-batch", self.n_batch,
                "--ctx-size", self.context_size,
            ]

            try:
                output = subprocess.check_output(cmd, text=True).strip()
                responses.append(output)
                context += f"\n{prompt}\n{one_line(output)}"
            except subprocess.CalledProcessError:
                responses.append("")

        return responses

<</mnt/linux-data/project/code/models/llm/finetuner.py>>
# models/llm/finetuner.py

import os
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq

def finetune_parser_model(
    model_name="t5-small",
    dataset_path="/mnt/linux-data/project/code/datasets/parser_examples.jsonl",
    output_dir="/mnt/linux-data/project/code/models/trained_models/parser-model",
    max_input_length=512,
    max_target_length=512,
    epochs=5,
    batch_size=8
):
    # Load base model and tokenizer
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

    # Load dataset
    raw_dataset = load_dataset("json", data_files=dataset_path, split="train")

    # Tokenization
    def preprocess(example):
        input_enc = tokenizer(example["input"], max_length=max_input_length, truncation=True)
        target_enc = tokenizer(example["output"], max_length=max_target_length, truncation=True)
        input_enc["labels"] = target_enc["input_ids"]
        return input_enc

    tokenized_dataset = raw_dataset.map(preprocess, remove_columns=["input", "output"])

    # Training arguments
    training_args = Seq2SeqTrainingArguments(
        output_dir=output_dir,
        per_device_train_batch_size=batch_size,
        num_train_epochs=epochs,
        save_strategy="epoch",
        logging_strategy="epoch",
        evaluation_strategy="no",
        save_total_limit=1,
        fp16=False,
        learning_rate=5e-5,
        overwrite_output_dir=True,
    )

    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)

    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_dataset,
        data_collator=data_collator,
        tokenizer=tokenizer,
    )

    trainer.train()
    trainer.save_model(output_dir)
    tokenizer.save_pretrained(output_dir)

    print(f"✅ Fine-tuned model saved to {output_dir}")

<</mnt/linux-data/project/code/models/llm/base_llm.py>>
from abc import ABC, abstractmethod
from typing import List

class BaseLLM(ABC):
    """
    Abstract base class for LLM interfaces.
    All language model implementations must inherit from this class and implement the following methods.
    """

    @abstractmethod
    def run(self, prompts: List[str]) -> List[str]:
        """
        Executes a list of prompts sequentially, preserving context.
        Returns a list of outputs.
        """
        raise NotImplementedError

    @abstractmethod
    def count_tokens(self, text: str) -> int:
        """
        Counts the number of tokens in the given text.
        """
        raise NotImplementedError
<</mnt/linux-data/project/code/blackboard/blackboard.py>>
def initialize_blackboard():
    """
    Returns a new initialized blackboard dictionary with empty/default values.

    Structure includes:
    - target information (IP, OS, services)
    - web directory status categorized by HTTP status codes
    - action history (agent logs, to be extended by API)

    Returns:
        dict: Initialized blackboard structure
    """
    return {
        "target": {
            "ip": "",
            "os": "",
            "services": [
                {"port": "", "protocol": "", "service": ""},
                {"port": "", "protocol": "", "service": ""},
                {"port": "", "protocol": "", "service": ""}
            ]
        },
        "web_directories_status": {
            "404": { "": "" },
            "200": { "": "" },
            "403": { "": "" },
            "401": { "": "" },
            "503": { "": "" }
        }
    }
<</mnt/linux-data/project/code/blackboard/blackboard_all.py>>
def initialize_blackboard():
    return {
        "attack_id": "",
        "target": {
            "ip": "",
            "os": "",
            "services": []
        },
        "exploit_metadata": {
            "exploit_id": None,
            "exploit_title": "",
            "exploit_language": None,
            "exploit_type": "",
            "source": "",
            "exploit_path": None
        },
        "exploit_code_raw": None,
        "code_static_features": {
            "functions": [],
            "syscalls_used": [],
            "payload_type": "",
            "encoding_methods": [],
            "obfuscation_level": "",
            "external_dependencies": [],
            "exploit_technique": ""
        },
        "connections_summary": {
            "total_connections": None,
            "total_packets": None,
            "protocols": [],
            "ports_involved": [],
            "flags_observed": [],
            "data_transferred_bytes": None,
            "sessions": []
        },
        "payload_analysis": [],
        "runtime_behavior": {
            "shell_opened": {
                "shell_type": "",
                "session_type": "",
                "shell_access_level": "",
                "authentication_method": "",
                "shell_session": {
                    "commands_run": []
                }
            }
        },
        "timestamps": {
            "first_packet": None,
            "last_packet": None
        },
        "attack_impact": {
            "success": None,
            "access_level": "",
            "shell_opened": None,
            "shell_type": "",
            "authentication_required": None,
            "persistence_achieved": None,
            "data_exfiltrated": [],
            "sensitive_info_exposed": [],
            "log_files_modified": [],
            "detected_by_defenses": None,
            "quality_score": None
        },
        "actions_log": [],
        "errors": [],
        "reward_log": [],
        "exploits_attempted": [],
        "explanation_of_attack": "",
        "exploit_analysis_detailed": []
    }


<</mnt/linux-data/project/code/blackboard/api.py>>
import time
import copy
import json

from config import BLACKBOARD_PATH

class BlackboardAPI:
    """
    Provides controlled access and updates to a shared blackboard dictionary.
    This class is used by agents to retrieve and modify the shared state.
    """

    def __init__(self, blackboard_dict: dict, json_path: str = BLACKBOARD_PATH):
        """
        Initialize the API with an external blackboard dictionary.

        Args:
            blackboard_dict (dict): A dictionary representing the shared state.
        """
        self.blackboard = blackboard_dict
        self.json_path = json_path
        self._save_to_file()
    
    def fill_state(self, actions_history: dict):
        self.blackboard["actions_history"] = actions_history.copy()
        self.blackboard["cpes"] = []
        self.blackboard["vulnerabilities_found"] = []
    
    def get_state_for_agent(self, agent_name: str) -> dict:
        """
        Return a deep copy of the current blackboard state for agent use.

        Args:
            agent_name (str): Name of the agent requesting the state.

        Returns:
            dict: A deep copy of the current state.
        """
        return copy.deepcopy(self.blackboard)

    def append_action_log(self, entry: dict):
        """
        Append an action entry to the action log with a timestamp.

        Args:
            entry (dict): The action log entry to append.
        """
        entry["timestamp"] = time.time()
        #self.blackboard.setdefault("actions_log", []).append(entry) Now for debuging
        self._save_to_file()

    def record_reward(self, action: str, reward: float):
        """
        Record a reward event for the last action taken.

        Args:
            action (str): The action associated with the reward.
            reward (float): The reward value.
        """
        entry = {
            "action": action,
            "reward": reward,
            "timestamp": time.time()
        }
        self.blackboard.setdefault("reward_log", []).append(entry)
        self._save_to_file()

    def add_error(self, agent: str, action: str, error: str):
        """
        Record an error that occurred during an agent's action.

        Args:
            agent (str): The name of the agent.
            action (str): The action that caused the error.
            error (str): The error message.
        """
        entry = {
            "agent": agent,
            "action": action,
            "error": error,
            "timestamp": time.time()
        }
        self.blackboard.setdefault("errors", []).append(entry)
        self._save_to_file()

    def get_last_actions(self, agent: str, n: int = 5):
        """
        Retrieve the last N actions performed by a specific agent.

        Args:
            agent (str): The agent name.
            n (int): Number of past actions to retrieve.

        Returns:
            list: List of recent action log entries.
        """
        return [
            log for log in reversed(self.blackboard.get("actions_log", []))
            if log.get("agent") == agent
        ][:n]

    def update_target_services(self, new_services: list):
        """
        Add new services to the target.services list if not already present.

        Args:
            new_services (list): List of service dicts to add.
        """
        existing = self.blackboard["target"].get("services", [])
        for service in new_services:
            if service not in existing:
                existing.append(service)
    
    def update_state(self, agent_name: str, new_state: dict):
        """
        Update the blackboard based on the agent name and the new state it provides.

        Args:
            agent_name (str): The name of the agent performing the update.
            new_state (dict): The new partial state information to merge.
        """
        if not isinstance(new_state, dict):
            raise ValueError("new_state must be a dictionary")

        # Example logic - call specific update methods based on agent type
        if agent_name.lower() == "reconagent":
            self._update_from_recon_agent(new_state)
        elif agent_name.lower() == "vulnagent":
            self._update_from_vuln_agent(new_state)
        else:
            raise ValueError(f"Unknown agent name: '{agent_name}'")

        self._save_to_file()

    def _update_from_recon_agent(self, new_state: dict):
        """
        Update fields relevant to ReconAgent.
        """
        if "target" in new_state:
            self.blackboard.setdefault("target", {}).update(new_state["target"])
        if "web_directories_status" in new_state:
            self.blackboard["web_directories_status"] = new_state["web_directories_status"]

    def _update_from_vuln_agent(self, new_state: dict):
        """
        Update fields relevant to VulnAgent.
        """
        if "cpes" in new_state:
            self.blackboard["cpes"] = new_state["cpes"]
        if "vulnerabilities_found" in new_state:
            self.blackboard["vulnerabilities_found"] = new_state["vulnerabilities_found"]

    def overwrite_blackboard(self, new_state: dict):
        """
        Overwrite the blackboard with a new state dictionary.

        Notes:
        - Completely clears the previous blackboard.
        - Does NOT preserve transient fields like 'actions_history'.

        Args:
            new_state (dict): The new state to replace the old one.
        """
        if not isinstance(new_state, dict):
            raise ValueError("new_state must be a dictionary")

        self.blackboard.clear()
        self.blackboard.update(new_state)
        self._save_to_file()
    
    def _save_to_file(self):
        try:
            with open(self.json_path, "w", encoding="utf-8") as f:
                json.dump(self.blackboard, f, indent=2)
        except Exception as e:
            print(f"[!] Failed to save blackboard to {self.json_path}: {e}")

<</mnt/linux-data/project/code/utils/json_fixer.py>>
import re
import json

from blackboard.blackboard import initialize_blackboard

def fix_malformed_json(text):
    """
    Attempts to fix common JSON syntax problems carefully.
    Fixes only known issues to avoid breaking valid JSONs.
    """
    # Remove ANSI escape codes (if any)
    text = re.sub(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])', '', text)

    # Fix cases where the status code key is missing quotation marks (e.g., "200": {/": "OK"})
    text = re.sub(r'"(\d{3})"\s*{(/\s*":\s*")', r'"\1": {"\2', text)

    # Fix missing closing quotation mark and colon for some cases like:
    # "200": /": "OK", --> "200": {"/": "OK"}
    text = re.sub(r'"/\s*":\s*([a-zA-Z0-9\s]+)"', r'"/": "\1"', text)

    # Handle cases where missing quotation marks or incorrect symbols
    text = re.sub(r'(\d{3}):\s*{/\s*":\s*', r'"\1": {"', text)

    # Ensure that strings have quotes (add if missing)
    text = re.sub(r'([a-zA-Z0-9_\-/]+)\s*:', r'"\1":', text)

    # Fix lines like "/path/: Status" → "/path/": "Status"
    def fix_key_value_line(match):
        key = match.group(1).strip()
        value = match.group(2).strip()
        if key and value and not key.endswith('"') and not value.startswith('"'):
            return f'"{key}": "{value}"'
        return match.group(0)  # leave unchanged

    text = re.sub(r'"(/[^"]*?):\s*([^"]+?)"', fix_key_value_line, text)

    # Remove stray broken key-value pairs like '"" : ""' with no comma
    text = re.sub(r'"\s*"\s*:\s*"\s*"\s*(?!,)', '"": "",', text)

    # Remove duplicate JSON blocks without comma between
    text = re.sub(r'}\s*{', '}, {', text)

    # Fix extra commas before closing
    text = re.sub(r",\s*([\]}])", r"\1", text)

    # Trim garbage outside JSON
    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1:
        text = text[start:end+1]

    # Auto-balance braces if needed
    open_count = text.count('{')
    close_count = text.count('}')
    if open_count > close_count:
        text += '}' * (open_count - close_count)

    return text

def extract_json_parts(noisy_text):
    """
    Extracts the different parts of the JSON structure from the noisy text.
    It finds specific values under 'target', 'os', 'ip', and 'web_directories_status' structure.
    :param noisy_text: The noisy text to extract information from.
    :return: A dictionary with extracted parts.
    """
    # First, fix any malformed JSON
    fixed_text = fix_malformed_json(noisy_text)
    
    parts = {}

    # Extracting "target" -> "ip"
    ip = extract_value_from_text(fixed_text, "ip", value_type="number")
    if ip:
        parts["target"] = {"ip": ip}

    # Extracting "target" -> "os"
    os = extract_value_from_text(fixed_text, "os", value_type="string")
    if os:
        if "target" not in parts:
            parts["target"] = {}
        parts["target"]["os"] = os

    # Extracting "target" -> "services"
    services = []
    service_matches = re.findall(r'"port": "(.*?)", "protocol": "(.*?)", "service": "(.*?)"', fixed_text)
    for match in service_matches:
        port, protocol, service = match
        services.append({"port": port, "protocol": protocol, "service": service})

    if services:
        if "target" not in parts:
            parts["target"] = {}
        parts["target"]["services"] = services

    # Extracting "web_directories_status"
    web_directories_status = {}
    status_matches = re.findall(r'"(\d{3})": {(.*?)}', fixed_text)
    for status, directories in status_matches:
        directories_dict = {}
        directories_list = re.findall(r'"(/.*?)": "(.*?)"', directories)
        for dir_path, status_text in directories_list:
            # Fixing missing " or :
            if not dir_path.startswith('"'):
                dir_path = '"' + dir_path
            if not dir_path.endswith('"'):
                dir_path = dir_path + '"'
            if not status_text.startswith('"'):
                status_text = '"' + status_text
            if not status_text.endswith('"'):
                status_text = status_text + '"'
            directories_dict[dir_path] = status_text
        web_directories_status[status] = directories_dict

    if web_directories_status:
        parts["web_directories_status"] = web_directories_status

    return parts

def extract_value_from_text(text, start_keyword, value_type="string"):
    """
    Extracts value after a keyword in the text.
    :param text: The input text to search in.
    :param start_keyword: The keyword to search for.
    :param value_type: Type of value to extract ("string", "number").
    :return: Extracted value.
    """
    pattern = re.compile(rf"{start_keyword}[^a-zA-Z0-9]*([a-zA-Z0-9\s\.]*)")
    match = re.search(pattern, text)
    if match:
        value = match.group(1).strip()
        if value_type == "number":
            # Extract the number only
            number_match = re.match(r"[\d.]+", value)
            if number_match:
                return number_match.group(0)
            else:
                return None
        return value
    return None

def print_json_parts(parts):
    """
    Recursively prints the contents of the JSON parts dictionary in a structured way.
    """
    def print_dict(d, indent=0):
        for key, value in d.items():
            if isinstance(value, dict):
                print(' ' * indent + f"{key}:")
                print_dict(value, indent + 2)
            elif isinstance(value, list):
                print(' ' * indent + f"{key}:")
                for i, item in enumerate(value):
                    print(f"{' ' * (indent + 2)}Item {i + 1}:")
                    print_dict(item, indent + 4)
            else:
                print(f"{' ' * indent}{key}: {value}")

    print_dict(parts)

def fill_json_structure(extracted_parts):
    """
    Fills the provided JSON template with extracted parts data, ensuring no overwriting of existing data
    and handling edge cases (e.g., malformed JSON, missing values).
    
    Arguments:
    template_json -- The initial JSON structure to be filled
    extracted_parts -- The dictionary containing the extracted parts data
    
    Returns:
    A filled and corrected JSON structure
    """
    # Initialize a clean template for the JSON (or use the existing one)
    template_json = initialize_blackboard()

    # === Step 1: Fill "target" section ===
    target = template_json.get("target", {})

    if "target" in extracted_parts:
        target_data = extracted_parts["target"]

        # Fill IP only if it's not already present
        if "ip" in target_data and not target.get("ip"):
            target["ip"] = target_data["ip"]

        # Fill OS only if it's not already present
        if "os" in target_data and not target.get("os"):
            target["os"] = target_data["os"]

        # Fill services only if it's not already present
        if "services" in target_data and not target.get("services"):
            target["services"] = target_data["services"]

        # Ensure all the services in the extracted data are added
        if "services" in target_data:
            existing_services = {service["port"]: service for service in target.get("services", [])}
            for service in target_data["services"]:
                # Add each service only if it's not already added
                if service["port"] not in existing_services:
                    target["services"].append(service)

    template_json["target"] = target

    # === Step 2: Fill "web_directories_status" section ===
    web_directories_status = template_json.get("web_directories_status", {})

    if "web_directories_status" in extracted_parts:
        wds_data = extracted_parts["web_directories_status"]

        for status, directories in wds_data.items():
            if status not in web_directories_status:
                web_directories_status[status] = {}
            for directory, value in directories.items():
                # Remove unnecessary escape characters like "\"/admin\""
                directory = directory.strip('"')
                value = value.strip('"')

                # Add directory only if it doesn't already exist
                if directory not in web_directories_status[status]:
                    web_directories_status[status][directory] = value

    template_json["web_directories_status"] = web_directories_status

    # === Step 3: Correct malformed structures (handling edge cases) ===
    # Loop over the JSON parts and fix missing or broken structures
    for section in ["target", "web_directories_status"]:
        if section in template_json:
            # If any dictionary is empty (like empty services or empty directories), fill with defaults
            if section == "target":
                if not template_json["target"].get("services"):
                    template_json["target"]["services"] = [{"port": "", "protocol": "", "service": ""}]
            if section == "web_directories_status":
                for status in ["200", "401", "403", "404", "503"]:
                    if status not in template_json["web_directories_status"]:
                        template_json["web_directories_status"][status] = {}

    # === Step 4: Remove empty services and empty directories ===
    final_json = remove_empty_services(template_json)
    final_json = clean_empty_directories_status(final_json)

    return final_json

def remove_empty_services(template_json):
    """
    Removes any services with empty values in the "services" list inside "target".
    
    Arguments:
    template_json -- The JSON structure that contains the "target" section
    
    Returns:
    The updated JSON structure with empty services removed
    """
    # Check if the 'target' and 'services' keys exist
    if "target" in template_json and "services" in template_json["target"]:
        # Filter out any service where any of the fields are empty
        template_json["target"]["services"] = [
            service for service in template_json["target"]["services"]
            if service.get("port") and service.get("protocol") and service.get("service")
        ]
    
    return template_json

def clean_empty_directories_status(json_data):
    """
    This function checks the 'web_directories_status' section in the full JSON data.
    If there are no directories (empty dictionary), it ensures that the entry with an empty key (": "") is present.
    If there are directories, it removes the entry with the empty key if it exists, and removes any additional occurrences of it.
    
    Arguments:
    json_data -- The full JSON data containing 'web_directories_status' among other parts
    
    Returns:
    json_data -- The updated JSON data with cleaned 'web_directories_status'
    """
    
    # Check if 'web_directories_status' exists in the json_data
    if "web_directories_status" in json_data:
        web_directories_status = json_data["web_directories_status"]
        
        # Loop over each status in web_directories_status
        for status, directories in web_directories_status.items():
            # Remove any occurrences of "": "" from the directories
            if "" in directories:
                del directories[""]  # Remove the empty key entry

            # If the status contains directories, we don't need to add an empty key
            if not directories:  # If no directories exist
                # Ensure that the empty key "" is present if no directories
                directories[""] = ""  # Add the empty key with empty value
    
    return json_data

def fix_json(text: str):
    parts = extract_json_parts(text)
    if parts:
        print("✅ JSON extracted successfully.")
        print_json_parts(parts)
    else:
        print("❌ Failed to extract valid JSON.")
    
    # Fill the JSON structure
    filled_json = fill_json_structure(parts)

    # Print result
    print(json.dumps(filled_json, indent=2))

    return filled_json

<</mnt/linux-data/project/code/utils/prompts.py>>
def PROMPT_1(current_state: str) -> str:
  return f""" You are about to receive a specific JSON structure. You must remember it exactly as-is.

Do not explain, summarize, or transform it in any way.
Just memorize it internally — you will be asked to use it later.
All response should be one line.

Here is the structure:
{current_state}
"""

def PROMPT_2(command_output: str, Custom_prompt: str) -> str:
  return f"""You were previously given a specific JSON structure. You MUST now return ONLY that same structure, filled correctly. Do NOT rename fields, add another keys, nest or restructure fileds, remove or replace any part of the format, guess or invent values, capitalize protocol or service names (use lowercase only). You MUST return JSON with exactly two top-level keys: "target" and "web_directories_status". Include all real fileds found, with no limit each status key must exist with {{"": ""}} if empty Do not change "ip" — always leave it as-is. Fill "os" only if the OS is clearly mentioned (e.g. "Linux", "Ubuntu", "Windows"). In "services", add an entry for each service found: "port": numeric (e.g. 22, 80) "protocol": "tcp" or "udp" (lowercase) "service": service name (e.g. http, ssh) — lowercase If missing, leave value as "". In "web_directories_status", for each status (200, 401, 403, 404, 503): Map any discovered paths (like "/admin") to their message (or use "" if no message). All five keys must appear, even if empty. If none found, keep {{ "": "" }}. Do not invent or guess data. Do not rename, add, or remove any fields. Return only the completed JSON. No extra text or formatting. Return only one-line compact JSON with same structure, no newlines, no indentations. All response should be one line. Instructions for this specific command: {Custom_prompt} Here is the new data: {command_output} Before returning your answer: Compare it to the original structure character by character Return ONLY ONE JSON — no explanation, no formatting, no comments"""

"""
You were previously given a specific JSON structure. You MUST now return ONLY that same structure, filled correctly.
Do NOT rename fields, add another keys, nest or restructure fileds, remove or replace any part of the format, guess or invent values, capitalize protocol or service names (use lowercase only).
You MUST return JSON with exactly two top-level keys: "target" and "web_directories_status".
Include all real fileds found, with no limit
each status key must exist with {{"": ""}} if empty
Do not change "ip" — always leave it as-is.
Fill "os" only if the OS is clearly mentioned (e.g. "Linux", "Ubuntu", "Windows").
In "services", add an entry for each service found:
"port": numeric (e.g. 22, 80)
"protocol": "tcp" or "udp" (lowercase)
"service": service name (e.g. http, ssh) — lowercase
If missing, leave value as "".
In "web_directories_status", for each status (200, 401, 403, 404, 503):
Map any discovered paths (like "/admin") to their message (or use "" if no message).
All five keys must appear, even if empty. If none found, keep {{ "": "" }}.
Do not invent or guess data.
Do not rename, add, or remove any fields.
Return only the completed JSON. No extra text or formatting.
Return only one-line compact JSON with same structure, no newlines, no indentations.
All response should be one line.
Instructions for this specific command:
{Custom_prompt}
Here is the new data:
{command_output}
Before returning your answer:
Compare it to the original structure character by character
Return ONLY ONE JSON — no explanation, no formatting, no comments
"""

def clean_output_prompt(raw_output: str) -> str:
    return f"""
You are given raw output from a network-related command.

🎯 Your task is to extract only the **critical technical reconnaissance data** relevant to identifying, fingerprinting, or mapping a **target system**.

❗ You do **NOT** know which command was used — it could be `whois`, `dig`, `nmap`, `nslookup`, `curl -I`, or any other.

✅ KEEP only the following:
- IP ranges, CIDRs, hostnames, domain names
- Open ports and services (e.g., "80/tcp open http")
- Server headers and fingerprinting info (e.g., Apache, nginx, PHP, IIS, versions)
- WHOIS identifiers: NetName, NetHandle, NetType, CIDR
- RFC references and technical timestamps (RegDate, Updated)
- Technical metadata directly describing network blocks or infrastructure

🛑 REMOVE everything else, including:
- Organization identity fields: `OrgName`, `OrgId`, `OrgTechName`, `OrgAbuseName`, etc.
- Geographical location: `City`, `Country`, `PostalCode`, `Address`
- Abuse or tech contact details: `OrgAbuseEmail`, `OrgTechEmail`, `Phone numbers`
- Legal disclaimers or registry policy messages (ARIN/RIPE/IANA)
- Any general comments, public notices, usage suggestions, or boilerplate text
- Duplicate fields or references (e.g., "Ref:", "Parent:")
- Empty fields, formatting headers, decorative characters

⚠️ DO NOT:
- Rephrase anything
- Add explanations or summaries
- Invent missing values

Return ONLY the cleaned, relevant technical output that a **penetration tester or AI agent** could use to understand the target system.

---

Here is the raw output:
---
{raw_output}
---

Return ONLY the cleaned output. No explanations, no formatting.
"""

def PROMPT_FOR_A_PROMPT(raw_output: str) -> str:
    return f"""
You are an LLM tasked with analyzing raw output from a reconnaissance command.

Your job is to generate **precise instructions** that guide another LLM on how to extract technical information from this specific output.  
🛠 The instructions must describe **how to interpret the output**, **what patterns to look for**, and **what information is relevant**.

🎯 Your output must:
- Identify the type of information present (e.g., IP, OS, ports, services)
- Specify **how to locate that data** (e.g., line structure, keywords, formats)
- Describe each relevant field that should be extracted
- Be tailored **specifically to this output** — not generic

❌ Do **NOT** include:
- Any example JSON structure
- Any explanations, summaries, or assumptions
- Any formatting instructions or extra commentary

📥 Here is the raw output to analyze:

{raw_output}

Very importent - It should be maximux 60 words!!!
No emojis!!
✏️ Return only a clear and focused list of extraction instructions based on the data in this output.
"""
<</mnt/linux-data/project/code/utils/utils.py>>
import re
import json
from utils.state_check.state_validator import validate_state

def extract_json_block(text_input):
    """
    Extracts the largest and most complete valid JSON block from noisy text.
    It cleans the input, finds all JSON-like blocks, parses them, validates them,
    and returns the best candidate.
    """

    # === Step 1: Convert input to string ===
    if isinstance(text_input, list):
        text = "\n".join(text_input)
    else:
        text = str(text_input)

    # === Step 2: Initial cleaning (remove ANSI codes, markdown, LLM artifacts) ===
    text = re.sub(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])', '', text)  # ANSI colors
    text = re.sub(r"```(?:json)?\s*({.*?})\s*```", r"\1", text, flags=re.DOTALL)  # strip ```json
    text = re.sub(r"```.*?```", "", text, flags=re.DOTALL)  # strip any code blocks
    text = re.sub(r"(The given JSON structure is:|Here is the structure:|You were previously given.*?)\n", "", text, flags=re.IGNORECASE)
    text = re.sub(r"The JSON structure provided.*?```", "", text, flags=re.DOTALL)
    text = re.sub(r"(?i)(you were previously given|return ONLY ONE JSON).*?{", "{", text, flags=re.DOTALL)
    text = re.sub(r",\s*([\]}])", r"\1", text)  # remove trailing commas

    # === Step 3: Find candidate JSON blocks using brace matching ===
    matches = []
    stack = []
    start = None

    for i, char in enumerate(text):
        if char == '{':
            if not stack:
                start = i
            stack.append('{')
        elif char == '}':
            if stack:
                stack.pop()
                if not stack and start is not None:
                    candidate = text[start:i + 1]
                    matches.append(candidate)

    # === Step 4: Attempt to parse each candidate JSON block ===
    valid_jsons = []

    for candidate in matches:
        candidate = candidate.strip()
        try:
            obj = json.loads(candidate)
            obj = one_line(obj)  # flatten
            valid_jsons.append((json.dumps(obj), obj))
        except json.JSONDecodeError as e:
            print(f"[!] JSONDecodeError: {e} — attempting to fix...")
            try:
                fixed = fix_malformed_json(candidate)
                obj = json.loads(validate_state(fixed))
                obj = one_line(obj)  # flatten
                valid_jsons.append((json.dumps(obj), obj))
            except Exception as e_inner:
                print(f"[!] Failed to fix JSON — {type(e_inner).__name__}: {e_inner}")
                continue
        except Exception as e:
            print(f"[!] Unexpected error — {type(e).__name__}: {e}")
            continue

        # Try to flatten the JSON into one line (optional visual clean-up)
        try:
            obj = one_line(obj)
        except:
            pass

        valid_jsons.append((json.dumps(obj), obj))
    
    if not valid_jsons:
        print("❌ No valid JSON found.")
        return None


    # === Step 5: Return the best valid JSON candidate ===

    # Select the largest (most complete) candidate
    best_candidate = max(valid_jsons, key=lambda pair: len(pair[0]))

    # === Step 6: Validate the JSON structure ===
    is_valid, validation_errors = validate_json_structure(best_candidate[1])
    if not is_valid:
        print("❌ Invalid JSON structure:")
        for e in validation_errors:
            print(" -", e)

    return best_candidate[1]

def fix_malformed_json(text):
    """
    Attempts to fix common JSON syntax problems carefully.
    Fixes only known issues to avoid breaking valid JSONs.
    """
    import re

    # Remove ANSI escape codes
    text = re.sub(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])', '', text)

    # Remove stray broken key-value pairs like '"" : ""' with no comma
    text = re.sub(r'"\s*"\s*:\s*"\s*"\s*(?!,)', '"": "",', text)

    # Remove duplicate JSON blocks without comma between
    text = re.sub(r'}\s*{', '}, {', text)

    # Fix extra commas before closing
    text = re.sub(r",\s*([\]}])", r"\1", text)

    # Fix lines like "/path/: Status" → "/path/": "Status"
    def fix_key_value_line(match):
        key = match.group(1).strip()
        value = match.group(2).strip()
        if key and value and not key.endswith('"') and not value.startswith('"'):
            return f'"{key}": "{value}"'
        return match.group(0)  # leave unchanged

    text = re.sub(r'"(/[^"]*?):\s*([^"]+?)"', fix_key_value_line, text)

    # Trim garbage outside JSON
    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1:
        text = text[start:end+1]

    # Auto-balance braces
    open_count = text.count('{')
    close_count = text.count('}')
    if open_count > close_count:
        text += '}' * (open_count - close_count)

    return text


EXPECTED_TOP_KEYS = {"target", "web_directories_status"}
EXPECTED_SERVICE_KEYS = {"port", "protocol", "service"}
EXPECTED_STATUS_CODES = {"200", "401", "403", "404", "503"}

def validate_json_structure(obj):
    """
    Validates that the object matches the strict schema for the penetration AI system.
    Returns (bool, list_of_errors)
    """
    errors = []

    if not isinstance(obj, dict):
        return False, ["Top-level is not a dictionary"]

    # Check top-level keys
    extra_keys = set(obj.keys()) - EXPECTED_TOP_KEYS
    missing_keys = EXPECTED_TOP_KEYS - set(obj.keys())
    if extra_keys:
        errors.append(f"Unexpected top-level keys: {extra_keys}")
    if missing_keys:
        errors.append(f"Missing top-level keys: {missing_keys}")

    # Validate "target"
    target = obj.get("target", {})
    if not isinstance(target, dict):
        errors.append("'target' must be a dictionary")
    else:
        if "ip" not in target or not isinstance(target["ip"], str):
            errors.append("Missing or invalid 'target.ip'")
        if "os" not in target or not isinstance(target["os"], str):
            errors.append("Missing or invalid 'target.os'")

        services = target.get("services", [])
        if not isinstance(services, list):
            errors.append("'target.services' must be a list")
        else:
            for i, service in enumerate(services):
                if not isinstance(service, dict):
                    errors.append(f"Service #{i} is not a dict")
                    continue
                keys = set(service.keys())
                if keys != EXPECTED_SERVICE_KEYS:
                    errors.append(f"Service #{i} has invalid keys: {keys}")

    # Validate "web_directories_status"
    wds = obj.get("web_directories_status", {})
    if not isinstance(wds, dict):
        errors.append("'web_directories_status' must be a dictionary")
    else:
        for status in EXPECTED_STATUS_CODES:
            if status not in wds:
                errors.append(f"Missing status code {status} in web_directories_status")
            elif not isinstance(wds[status], dict):
                errors.append(f"Status code {status} value is not a dictionary")

    return len(errors) == 0, errors

def remove_comments_and_empty_lines(text: str) -> str:
    """
    Removes comment lines (starting with '#') and empty lines from a multiline string.

    Parameters:
        text (str): Multiline string.

    Returns:
        str: Cleaned text.
    """
    cleaned_lines = []
    for line in text.splitlines():
        stripped = line.strip()
        if stripped and not stripped.startswith("#"):
            cleaned_lines.append(line)
    return "\n".join(cleaned_lines)

def one_line(text: str) -> str:
    """
    Convert a multi-line string into a clean single line.
    """
    return ' '.join(line.strip() for line in text.strip().splitlines() if line).replace('  ', ' ')


# Example debug run
def main():
    text_input = [
        '[Some prompt text\n\n{\n  "target": {\n    "ip": "",\n    "os": "Unknown"\n  }\n}\x1b[0m\n',
        '{\n  "target": {\n    "ip": "",\n    "os": "Unknown"\n  }\n}\x1b[0m\n'
    ]

    result = extract_json_block(text_input)
    print("✅ Extracted JSON:")
    print(json.dumps(result, indent=2))


if __name__ == "__main__":
    main()

<</mnt/linux-data/project/code/utils/state_check/state_correctness.py>>
import subprocess
import re
import json
from utils.utils import remove_comments_and_empty_lines
from config import TARGET_IP
from utils.state_check.state_validator import clean_web_directories

def run_command(cmd: str) -> str:
    try:
        result = subprocess.check_output(cmd.split(), timeout=10).decode()
        return remove_comments_and_empty_lines(result)
    except:
        return ""

def check_port_with_nmap(ip: str, port: str) -> str:
    output = run_command(f"nmap -sV -p {port} {ip}")
    #print(f"[DEBUG] nmap output for port {port}:\n{output}")

    for line in output.splitlines():
        # בדוק שהפורט פתוח, גם אם אין שם שירות
        if re.match(rf"^{port}/tcp\s+open", line):
            match = re.match(rf"^{port}/tcp\s+open\s+(\S+)", line)
            if match:
                return match.group(1).lower()
            else:
                print(f"[!] Could not determine service on open port {port}/tcp — marking as 'unknown'")
                return "unknown"

    print(f"[!] Port {port}/tcp is not open — skipping.")
    return None

def detect_os_from_multiple_tools(ip: str, current_os: str) -> str:
    tools = [
        f"whatweb http://{ip}",
        f"curl -I http://{ip}",
        f"wget http://{ip} -O -"
    ]

    os_candidates = []

    for cmd in tools:
        output = run_command(cmd)
        if "linux" in output.lower():
            os_candidates.append("Linux")
        elif "windows" in output.lower():
            os_candidates.append("Windows")
        elif "ubuntu" in output.lower():
            os_candidates.append("Linux")
        elif "iis" in output.lower():
            os_candidates.append("Windows")
        elif "apache" in output.lower() or "nginx" in output.lower():
            os_candidates.append("Linux")

    if os_candidates:
        if "Linux" in os_candidates:
            return "Linux"
        return os_candidates[0]

    return current_os

EXPECTED_CODES = ["200", "401", "403", "404", "503"]

def verify_web_directories(ip: str, web_dirs: dict) -> dict:
    """
    מאמת נתיבי Web מול השרת וממקם כל נתיב בקטגוריית הסטטוס האמיתית בלבד.
    בנוסף, מסיר "" ריקים אם קיימים נתיבים תקניים.
    """
    verified = {code: {} for code in EXPECTED_CODES}

    for code, entries in web_dirs.items():
        for path in entries:
            full_url = f"http://{ip}{path}"
            try:
                response = subprocess.check_output(
                    ["curl", "-i", "-s", full_url],
                    timeout=5
                ).decode()

                # מציאת שורת ה־HTTP
                first_line = next((line for line in response.splitlines() if line.startswith("HTTP/")), "")
                parts = first_line.strip().split(" ", 2)
                status_code = parts[1] if len(parts) > 1 else "404"
                reason = parts[2] if len(parts) > 2 else ""

                # ניקוי הקוד
                status_code = status_code.strip()
                reason = reason.strip()

                if status_code in verified:
                    verified[status_code][path] = reason
                else:
                    verified["404"][path] = reason or "Unknown"

            except Exception:
                verified["404"][path] = "Error or Timeout"

    # הסרת "" מיותר ויישור סופי של המבנה
    verified = clean_web_directories(verified)
    return verified

def correct_state(state: dict) -> dict:
    ip = TARGET_IP

    print(f"[+] Verifying declared services individually on {ip}...")

    verified_services = []
    for s in state.get("target", {}).get("services", []):
        port = s.get("port", "")
        protocol = s.get("protocol", "").lower()
        declared_service = s.get("service", "").lower()

        if not port or not protocol or protocol != "tcp":
            continue  # מדלגים על שורות פגומות או שאינן TCP

        actual_service = check_port_with_nmap(ip, port)
        if actual_service:
            verified_services.append({
                "port": port,
                "protocol": "tcp",
                "service": actual_service  # יכול להיות שונה מהצהרה
            })
        else:
            print(f"[!] Port {port}/tcp is not open — removing.")

    state["target"]["services"] = verified_services

    # OS detection
    current_os = state["target"].get("os", "Unknown")
    new_os = detect_os_from_multiple_tools(ip, current_os)
    state["target"]["os"] = new_os

    # Web directories
    print(f"[+] Verifying web directories with curl...")
    raw_web_dirs = verify_web_directories(ip, state.get("web_directories_status", {}))
    state["web_directories_status"] = clean_web_directories(raw_web_dirs)

    return state

<</mnt/linux-data/project/code/utils/state_check/state_validator.py>>
import re

VALID_PROTOCOLS = {"tcp", "udp"}
EXPECTED_WEB_CODES = ["200", "401", "403", "404", "503"]

def ensure_structure(state: dict) -> dict:
    """
    מוודא שכל שדות החובה קיימים במבנה ה־state.
    """
    state.setdefault("target", {})
    state["target"].setdefault("ip", "")
    state["target"].setdefault("os", "")
    state["target"].setdefault("services", [])

    # עבור כל שירות ברשימה, ודא שהפורט, הפרוטוקול והשירות קיימים, אחרת הסר את השירות
    state["target"]["services"] = [
        service for service in state["target"]["services"]
        if service.get("port") and service.get("protocol") and service.get("service")
    ]

    state.setdefault("web_directories_status", {})
    for code in EXPECTED_WEB_CODES:
        state["web_directories_status"].setdefault(code, {"": ""})

    return state

def validate_services_format(services: list) -> list:
    """
    מוודא שכל שירות במבנה תקני: פורט מספרי, פרוטוקול tcp/udp, ושם שירות באנגלית.
    """
    valid = []
    for s in services:
        try:
            port = int(s.get("port", ""))
            protocol = s.get("protocol", "").lower()
            service = s.get("service", "").lower()
            if (
                0 < port <= 65535 and
                protocol in VALID_PROTOCOLS and
                re.match(r'^[a-z0-9\-_\.]+$', service)
            ):
                valid.append({
                    "port": str(port),
                    "protocol": protocol,
                    "service": service
                })
        except:
            continue
    return valid

def filter_invalid_services(services: list) -> list:
    """
    מסנן שירותים פיקטיביים לפי פורטים או שמות בעייתיים.
    """
    suspicious_ports = {0, 1, 9999}
    blocked_names = {"none", "fake"}

    return [
        s for s in services
        if int(s["port"]) not in suspicious_ports
        and s["service"] not in blocked_names
    ]

def clean_web_directories(web_dirs: dict) -> dict:
    """
    מנקה ומוודאת את מבנה web_directories_status:
    - שומר רק נתיבים חוקיים שמתחילים ב-"/".
    - מוסיף '"" : ""' רק אם היה לפחות נתיב עם '/'.
    - תמיד מחזיר את כל חמשת הקטגוריות: 200, 401, 403, 404, 503.
    """
    cleaned = {}
    expected_codes = ["200", "401", "403", "404", "503"]

    for code in expected_codes:
        entries = web_dirs.get(code, {})
        valid_paths = {}

        has_slash_path = False

        if isinstance(entries, dict):
            for path, label in entries.items():
                if isinstance(path, str) and isinstance(label, str):
                    if path.startswith("/") and path.strip():
                        valid_paths[path] = label
                        has_slash_path = True  # היה לפחות נתיב אמיתי

        # אם לא היו נתיבים חוקיים בכלל — נשאיר "": ""
        # אם כן היו נתיבים עם "/", נכניס "": "" גם
        if not has_slash_path:
            valid_paths[""] = ""

        cleaned[code] = valid_paths

    return cleaned

def truncate_lists(state: dict, max_services=100, max_paths_per_status=100) -> dict:
    """
    מגביל את האורך של services ונתיבי web.
    """
    state["target"]["services"] = state["target"]["services"][:max_services]
    for code in EXPECTED_WEB_CODES:
        entries = state["web_directories_status"].get(code, {})
        limited = dict(list(entries.items())[:max_paths_per_status])
        state["web_directories_status"][code] = limited
    return state

def validate_state(state: dict) -> dict:
    """
    פונקציה ראשית שמיישמת את כל שלבי הבדיקה והניקוי.
    """
    state = ensure_structure(state)
    services = state["target"]["services"]
    services = validate_services_format(services)
    services = filter_invalid_services(services)
    state["target"]["services"] = services

    state["web_directories_status"] = clean_web_directories(state["web_directories_status"])
    state = truncate_lists(state)
    return state
<</mnt/linux-data/project/code/encoders/state_encoder.py>>
import hashlib
import json
import torch
import numbers
import numpy as np

class StateEncoder:
    """
    Encodes complex nested blackboard state structures into fixed-length numerical vectors
    suitable for use as input to neural networks.
    """

    def __init__(self, action_space: list, max_features: int = 128):
        """
        Args:
            action_space (list): List of all valid action strings.
            max_features (int): Fixed length of the output state vector.
        """
        self.encoded_to_state = {}  # Maps stringified vectors to original state dicts
        self.max_features = max_features
        self.action_space = action_space
        self.action_to_index = {action: i for i, action in enumerate(action_space)}

    def base100_encode(self, text: str) -> float:
        """
        Encodes a string to a base-100 floating point number in [0, 1).

        Args:
            text (str): Input string (e.g., service name, OS, etc.)

        Returns:
            float: Encoded value between 0 and 1.
        """
        base = 100
        code = 0
        for i, c in enumerate(text[:5]):
            code += ord(c) * (base ** (4 - i))
        max_code = (base ** 5) - 1
        return code / max_code

    def encode(self, state: dict, actions_history: list) -> torch.Tensor:
        """
        Converts the blackboard state and action history into a fixed-length torch vector.

        Args:
            state (dict): The full blackboard state.
            actions_history (list): List of actions executed by the agent so far.

        Returns:
            torch.Tensor: A vector of shape (max_features,) representing the state.
        """
        # Flatten the state
        flat_state = self._flatten_state(state)

        # Encode action history as one-hot
        actions_vector = np.zeros(len(self.action_space), dtype=np.float32)
        for action in actions_history:
            if action in self.action_to_index:
                idx = self.action_to_index[action]
                actions_vector[idx] += 1.0 # To count the number of time that command ran

        # Add action history to the flat dictionary
        for i, val in enumerate(actions_vector):
            flat_state[f"action_history_idx_{i}"] = val

        # Sort keys to ensure consistent ordering
        sorted_items = sorted(flat_state.items())
        encoded_values = [self._normalize_value(k, v) for k, v in sorted_items]

        # Pad or truncate to fixed length
        if len(encoded_values) < self.max_features:
            encoded_values += [0.0] * (self.max_features - len(encoded_values))
        else:
            encoded_values = encoded_values[:self.max_features]

        # Convert to tensor
        vector = torch.tensor(encoded_values, dtype=torch.float32)

        # Store reverse mapping for debug and reward tracking
        vector_key = str(vector.tolist())
        self.encoded_to_state[vector_key] = state

        print(f"[Encoder] Encoded vector of length {len(encoded_values)} (state + history)")
        return vector

    def decode(self, vector_key: str) -> dict:
        """
        Retrieves the original state dictionary corresponding to a previously encoded vector.

        Args:
            vector_key (str): The stringified vector key.

        Returns:
            dict: The original blackboard state (if exists).
        """
        return self.encoded_to_state.get(vector_key, {})

    def _flatten_state(self, obj, prefix='') -> dict:
        """
        Flattens a nested dictionary or list into a single-level dict of key→value.

        Args:
            obj: The structure to flatten.
            prefix: Internal prefix used for recursion.

        Returns:
            dict: Flattened key-value pairs.
        """
        items = {}

        if prefix.endswith("vulnerabilities_found"):
            return {}

        if isinstance(obj, dict):
            for k, v in obj.items():
                full_key = f"{prefix}.{k}" if prefix else k
                items.update(self._flatten_state(v, full_key))
        elif isinstance(obj, list):
            for i, v in enumerate(obj):
                full_key = f"{prefix}[{i}]"
                items.update(self._flatten_state(v, full_key))
        elif isinstance(obj, bool):
            items[prefix] = 1.0 if obj else 0.0
        elif isinstance(obj, numbers.Number):
            items[prefix] = float(obj)
        elif isinstance(obj, str):
            items[prefix] = self.base100_encode(obj)
        else:
            items[prefix] = 0.0

        return items

    def _normalize_value(self, key: str, value: float) -> float:
        """
        Normalizes values based on the type of field they represent.

        Args:
            key (str): Feature name (used to detect type like "port", "service", etc.)
            value (float): The numeric value to normalize.

        Returns:
            float: Normalized value between 0 and 1.
        """
        if isinstance(value, (int, float)):
            if "port" in key:
                return min(value / 65535.0, 1.0)
            elif "protocol" in key:
                return min(value / 3.0, 1.0)
            elif "action_history" in key:
                return float(value)
            elif any(field in key for field in ["service", "web_directories_status", "os"]):
                return min(value / 1e6, 1.0)
            else:
                return min(value / 1e6, 1.0)
        return 0.0

<</mnt/linux-data/project/code/encoders/action_encoder.py>>
from typing import List

class ActionEncoder:
    """
    Encodes and decodes actions using consistent index-based mappings.
    Converts between string-based actions and their numeric representation.
    """

    def __init__(self, actions: List[str]):
        """
        Args:
            actions (List[str]): List of possible action strings.
        """
        self.action_to_index = {action: i for i, action in enumerate(actions)}
        self.index_to_action = {i: action for i, action in enumerate(actions)}

    def encode(self, action: str) -> int:
        """
        Converts an action string to its corresponding index.

        Args:
            action (str): Action command (e.g., "nmap -sV {ip}")

        Returns:
            int: Index of the action in the action space.

        Raises:
            KeyError: If the action is not in the known action space.
        """
        if action not in self.action_to_index:
            raise KeyError(f"Action '{action}' not found in action space.")
        return self.action_to_index[action]

    def decode(self, index: int) -> str:
        """
        Converts an action index back to its corresponding command string.

        Args:
            index (int): Index in the action space.

        Returns:
            str: Action command string.

        Raises:
            KeyError: If the index is out of bounds.
        """
        if index not in self.index_to_action:
            raise KeyError(f"Index {index} is not valid in action space.")
        return self.index_to_action[index]

