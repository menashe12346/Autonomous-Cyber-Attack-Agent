from transformers import AutoModelForCausalLM, AutoTokenizer

# ×©× ×”××•×“×œ ×¢×œ HuggingFace
model_name = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"

# × ×ª×™×‘ ×©××•×ª×× ×œ×¤×§×•×“×ª ×”××™××•×Ÿ ×©×œ×š
save_path = "/mnt/linux-data/project/code/models/hf_models/mistral"

print(f"[ğŸš€] Downloading TinyLlama model ({model_name})...")
model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

print(f"[ğŸ’¾] Saving model and tokenizer to: {save_path}")
model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

print("[âœ…] Done! You can now run your training script.")
